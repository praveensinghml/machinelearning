{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxXcjDT_s8yl"
      },
      "outputs": [],
      "source": [
        "### https://www.kaggle.com/code/abhishek/approaching-almost-any-nlp-problem-on-kaggle/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e916ByKBvfsT"
      },
      "source": [
        "we will use below list of technique\n",
        "\n",
        "1. tfidf\n",
        "2. count features\n",
        "3. logistic regression\n",
        "4. naive bayes\n",
        "5. svm\n",
        "6. xgboost\n",
        "7. grid search\n",
        "8. word vectors\n",
        "9. LSTM\n",
        "10. GRU\n",
        "11. Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIxLd0XoYHIU",
        "outputId": "84989d80-e5c8-4e08-b158-62fdd913a87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        " import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0PzvlNZtHKr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QOAFd5OwKpH"
      },
      "outputs": [],
      "source": [
        "df_train= pd.read_csv(\"/content/drive/MyDrive/ML_DATASET/spooky/train.csv\")\n",
        "df_test= pd.read_csv(\"/content/drive/MyDrive/ML_DATASET/spooky/test.csv\")\n",
        "df_sample= pd.read_csv(\"/content/drive/MyDrive/ML_DATASET/spooky/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uy31KwzPzr1C",
        "outputId": "d8280382-6c46-4b99-e279-9905d6bdf4f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20879d98-2edd-41a4-92d2-4744b284ebdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20879d98-2edd-41a4-92d2-4744b284ebdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20879d98-2edd-41a4-92d2-4744b284ebdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20879d98-2edd-41a4-92d2-4744b284ebdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_FKJ9b33zziz",
        "outputId": "dd2583cb-b9f3-4707-83b0-0377633ea729"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text\n",
              "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
              "1  id24541  If a fire wanted fanning, it could readily be ...\n",
              "2  id00134  And when they had broken down the frail door t...\n",
              "3  id27757  While I was thinking how I should possibly man...\n",
              "4  id04081  I am not sure to what limit his knowledge may ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0fd8899-5d1e-460f-a2f2-ce31b27b6b85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>And when they had broken down the frail door t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>While I was thinking how I should possibly man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>I am not sure to what limit his knowledge may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0fd8899-5d1e-460f-a2f2-ce31b27b6b85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0fd8899-5d1e-460f-a2f2-ce31b27b6b85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0fd8899-5d1e-460f-a2f2-ce31b27b6b85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T1Nf35lMz27N",
        "outputId": "f382dafb-989c-4031-e681-23fd93d36d48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id       EAP       HPL       MWS\n",
              "0  id02310  0.403494  0.287808  0.308698\n",
              "1  id24541  0.403494  0.287808  0.308698\n",
              "2  id00134  0.403494  0.287808  0.308698\n",
              "3  id27757  0.403494  0.287808  0.308698\n",
              "4  id04081  0.403494  0.287808  0.308698"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1c96ad4-6559-4c71-b189-30d73b3aa822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1c96ad4-6559-4c71-b189-30d73b3aa822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1c96ad4-6559-4c71-b189-30d73b3aa822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1c96ad4-6559-4c71-b189-30d73b3aa822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd4zyGcKz6Q6",
        "outputId": "cdeabcfb-2a03-4ddf-a807-284ac16721ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Shape:  (19579, 3)\n",
            "===============================\n",
            "Test Shape:  (8392, 2)\n",
            "===============================\n",
            "sample Shape:  (8392, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Shape: \", df_train.shape)\n",
        "print(\"===============================\")\n",
        "print(\"Test Shape: \", df_test.shape)\n",
        "print(\"===============================\")\n",
        "print(\"sample Shape: \", df_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxbG1mbnrEGY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "DxmSBXttrCGC",
        "outputId": "64acdeb2-9d85-4018-872b-441666d60c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Data Analysis')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = df_train.author.value_counts()\n",
        "sns.barplot(x.index, x)\n",
        "plt.gca().set_ylabel(\"Target\")\n",
        "plt.gca().set_xlabel(\"Train Data Analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copiQQZqZbJn"
      },
      "source": [
        "**Multiclass Lebels**\n",
        "The problem requires us to predict the author, i.e. EAP, HPL and MWS given the text. In simpler words, text classification with 3 different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJXFUPaX0mq2"
      },
      "outputs": [],
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3d1r1f3Z-IS"
      },
      "source": [
        "# **Using Label Encoder**\n",
        " Convert text to labels into 0,1,2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SffczGZY4bB"
      },
      "outputs": [],
      "source": [
        "lblEncoder = preprocessing.LabelEncoder()\n",
        "y = lblEncoder.fit_transform(df_train.author.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuKKc-SLaeO3"
      },
      "outputs": [],
      "source": [
        "# set(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw0Hyf3-alqX"
      },
      "source": [
        "Splitting Data set in Train and Test using **model_selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvq5lxSXaevJ"
      },
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(df_train.text.values, y, \n",
        "                                                  stratify=y, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KimFGOtbbZG2"
      },
      "source": [
        " **stratify** It is used to split random data based on classifier labels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3VSxP2ra-vx",
        "outputId": "c4306754-de73-4a58-938b-1f0ba7ece087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17621,)\n",
            "(1958,)\n"
          ]
        }
      ],
      "source": [
        "print (xtrain.shape)\n",
        "print (xvalid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVNLirPTbu-5"
      },
      "source": [
        "## Building Basic ModelsÂ¶\n",
        "Let's start building our very first model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vnEPUqVbn0y"
      },
      "outputs": [],
      "source": [
        "tfv = TfidfVectorizer(min_df = 3, max_features=None, strip_accents='unicode',\n",
        "                        analyzer='word', token_pattern=r'\\w{1,}',\n",
        "                        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
        "                        stop_words = 'english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3sko24acUgF"
      },
      "outputs": [],
      "source": [
        "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
        "tfv.fit(list(xtrain) +  list(xvalid))\n",
        "xtrain_tfv =  tfv.transform(xtrain) \n",
        "xvalid_tfv = tfv.transform(xvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXx8m-TLckye",
        "outputId": "640ebc26-f11b-40a1-8273-2eee47203108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.572 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple Logistic Regression on TFIDF\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNE9oFZdscW"
      },
      "source": [
        "Let's use another approach to get more better result **CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaTOajYvd5Ps"
      },
      "outputs": [],
      "source": [
        "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), stop_words = 'english')\n",
        "\n",
        "ctv.fit(list(xtrain) + list(xvalid))\n",
        "cv_train = ctv.transform(xtrain)\n",
        "cv_test = ctv.transform(xvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oFCd1zXc9v-",
        "outputId": "1af5b8ad-8ab7-43d9-f5e2-6935f9082881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.527 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple Logistic Regression on CV\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(cv_train, ytrain)\n",
        "predictions = clf.predict_proba(cv_test)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHUi22nie0uf"
      },
      "source": [
        "We found improvement in logloss! and looks better than **TFIDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wgACZs6fLc1"
      },
      "source": [
        "Now trying to change Model using **Naive Bayes on CV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwiPdhAqen_U",
        "outputId": "a08ca61e-a44c-422f-944c-bc071d857f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.485 \n"
          ]
        }
      ],
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(cv_train, ytrain)\n",
        "predictions = clf.predict_proba(cv_test)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdGmMP8RtDrN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoUgq6Wgfp1Z"
      },
      "source": [
        "Now we got much better than Logistic regression using Naive Bayes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "migoU-i9fx13"
      },
      "outputs": [],
      "source": [
        "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xvalid_svd = svd.transform(xvalid_tfv)\n",
        "\n",
        "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OazDaxpqgq0Q",
        "outputId": "0c1e2490-3495-47dd-ae02-1a7f2a6cdecc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.041897  , -0.00794377, -0.0053988 , ...,  0.02402336,\n",
              "         0.02012188, -0.00315865],\n",
              "       [ 0.08478728,  0.22555022,  0.00421333, ..., -0.00334057,\n",
              "         0.0168713 ,  0.03786612],\n",
              "       [ 0.05793769, -0.02006542,  0.0009317 , ..., -0.01340451,\n",
              "         0.00251665,  0.03805849],\n",
              "       ...,\n",
              "       [ 0.02381288,  0.00071342, -0.00050204, ..., -0.05575203,\n",
              "        -0.02014242, -0.00995765],\n",
              "       [ 0.08784847, -0.00655745, -0.00982831, ...,  0.02085094,\n",
              "        -0.04386557, -0.03563842],\n",
              "       [ 0.01994066, -0.00104047, -0.00034871, ...,  0.00039374,\n",
              "         0.00113875,  0.00843948]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "xtrain_svd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CagY_Hjvg0ud",
        "outputId": "8bda936a-2101-4f0c-854f-0ee50b80744a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.735 \n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple SVM\n",
        "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
        "clf.fit(xtrain_svd_scl, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd_scl)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0vXnz02hEQu"
      },
      "source": [
        "Oops! time to get up! Looks like SVM doesn't perform well on this data...!\n",
        "\n",
        "Before moving further, lets apply the most popular algorithm on Kaggle: xgboost!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mTza6xJhb3X"
      },
      "source": [
        "# TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh3KqfmAg74I",
        "outputId": "09581ac2-eade-4a16-cf79-db159d5078df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.782 \n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple xgboost on tf-idf\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdzOrtLshPMl",
        "outputId": "457c0588-2f69-4620-94eb-4f799a964df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1958x15102 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 22260 stored elements in Compressed Sparse Column format>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "xvalid_tfv.tocsc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3la-rechghT"
      },
      "source": [
        "# CV - CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_g_wUVZhf3r",
        "outputId": "4f1a5eba-504d-42ee-8c78-462b52a62508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.773 \n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple xgboost on tf-idf\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(cv_train, ytrain)\n",
        "predictions = clf.predict_proba(cv_test)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty2q1cD3jRuM",
        "outputId": "517eac70-9e5c-4c44-a073-6dc003f2edc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logloss: 0.817 \n"
          ]
        }
      ],
      "source": [
        "# Fitting a simple xgboost on tf-idf svd features\n",
        "clf = xgb.XGBClassifier(nthread=10)\n",
        "clf.fit(xtrain_svd, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9AJHCuQoBXE"
      },
      "source": [
        "**Creating scorer **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BYg5xaAn0-B"
      },
      "outputs": [],
      "source": [
        "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKr8rDJOn_0a"
      },
      "outputs": [],
      "source": [
        "# Initialize SVD\n",
        "svd = TruncatedSVD()\n",
        "    \n",
        "# Initialize the standard scaler \n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "# We will use logistic regression here..\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('svd', svd),\n",
        "                         ('scl', scl),\n",
        "                         ('lr', lr_model)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhlQHlm-oiGY"
      },
      "outputs": [],
      "source": [
        "param_grid = {'svd__n_components' : [120, 180],\n",
        "              'lr__C': [0.1, 1.0, 10], \n",
        "              'lr__penalty': ['l1', 'l2']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHhEn8rholoC",
        "outputId": "54169586-e495-4e2d-b5b4-5b2966c72685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "12 fits failed out of a total of 24.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [        nan         nan -0.77577711 -0.74203227         nan         nan\n",
            " -0.77860509 -0.7394813          nan         nan -0.77011275 -0.74291614]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: -0.739\n",
            "Best parameters set:\n",
            "\tlr__C: 1.0\n",
            "\tlr__penalty: 'l2'\n",
            "\tsvd__n_components: 180\n"
          ]
        }
      ],
      "source": [
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1,  refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqdKtQ2oyIU",
        "outputId": "423e4b8c-41cc-4321-b666-48cf32a40170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "Best score: -0.492\n",
            "Best parameters set:\n",
            "\tnb__alpha: 0.1\n"
          ]
        }
      ],
      "source": [
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('nb', nb_model)])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggu5EhiQpw_t"
      },
      "source": [
        "# Word VectorsÂ¶\n",
        "\n",
        "\n",
        "1. GloVe vectors\n",
        "2. word2vec\n",
        "3. fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfpr6HHEpqIL",
        "outputId": "d61d993f-e242-482b-943c-c4f91b0c0ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 210185 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embedding_dict={}\n",
        "with open('/content/drive/MyDrive/ML_DATASET/glove.6B.100d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values=line.split()\n",
        "        word=values[0]\n",
        "        vectors=np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word]=vectors\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embedding_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NaqxI6au2cC",
        "outputId": "111cc848-d0f6-4047-907e-276b976bcf74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aztwh9A5pnvl"
      },
      "outputs": [],
      "source": [
        "# this function creates a normalized vector for the whole sentence\n",
        "def sent2vec(s):\n",
        "    words = s.lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    words = [w for w in words if w.isalpha()]\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(embedding_dict[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    if type(v) != np.ndarray:\n",
        "        return np.zeros(300)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEGZJYfBujab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a92b28c-8b30-4367-8cf0-4ef433ffd46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 17621/17621 [00:05<00:00, 2949.27it/s]\n",
            "100%|ââââââââââ| 1958/1958 [00:00<00:00, 2911.04it/s]\n"
          ]
        }
      ],
      "source": [
        "# create sentence vectors using the above function for training and validation set\n",
        "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
        "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "5x4FZ_MZukvC",
        "outputId": "7a4ce76d-87fa-4a46-ce27-d0cfd1d4bffb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0d0f3f68c540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxvalid_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "xvalid_glove = np.array(xvalid_glove, dtype=object)\n",
        "xtrain_glove = np.array(xtrain_glove, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9A9Qb8IIBn2",
        "outputId": "131f271a-95c4-4379-9830-8cf561e35f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "xtrain_glove.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1Ksmk11IXLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fd0364-e23b-4ed3-fe73-8a579530f0db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621,)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "ytrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqtd_5U0vKN4"
      },
      "outputs": [],
      "source": [
        "# Fitting a simple xgboost on glove features\n",
        "clf = xgb.XGBClassifier(nthread=10, silent=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "887e9dhfJl9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "220970ae-d81a-4782-e9c8-5ddb2db4f078"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ee9b97e566ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "clf.fit(xtrain_glove, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict_proba(xvalid_glove)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "metadata": {
        "id": "57_ZtS7BJRQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t21soXpKJcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "7afde870-1be2-4263-d967-32407fbb01c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f11a38b679b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n\u001b[1;32m      3\u001b[0m                         subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "# Fitting a simple xgboost on glove features\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n",
        "clf.fit(xtrain_glove, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_glove)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBLrZfA-MB_l"
      },
      "source": [
        "# Deep LearningÂ¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS3I44EDMuDz"
      },
      "outputs": [],
      "source": [
        "def create_corpus(df):\n",
        "    corpus=[]\n",
        "    for tweet in tqdm(df['text']):\n",
        "        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop_words))]\n",
        "        corpus.append(words)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrKyY7fEMui-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b02e7c-24bf-4b39-a639-14a9b41b0c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 27971/27971 [00:08<00:00, 3360.86it/s]\n"
          ]
        }
      ],
      "source": [
        "df = df_train.append(df_test)\n",
        "corpus=create_corpus(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2kFBMe8OBCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a346c1ac-02d6-4bf2-e036-608234d6b9f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "ytrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kapXkp7sN_LV"
      },
      "outputs": [],
      "source": [
        "# we need to binarize the labels for the neural net\n",
        "ytrain_enc = np_utils.to_categorical(ytrain)\n",
        "yvalid_enc = np_utils.to_categorical(yvalid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZd5-o8pOEtG"
      },
      "outputs": [],
      "source": [
        "# create a simple 3 layer sequential neural net\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(300, input_dim=300, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xin54OTOK9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "0aa5d124-1497-4beb-9a03-6f9b6bc0a2a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-92a5b2e206aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(xtrain_glove, y=ytrain_enc, batch_size=64, \n\u001b[0;32m----> 2\u001b[0;31m           epochs=5, verbose=1,  validation_data=(xvalid_glove, yvalid_enc))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ],
      "source": [
        "model.fit(xtrain_glove, y=ytrain_enc, batch_size=64, \n",
        "          epochs=5, verbose=1,  validation_data=(xvalid_glove, yvalid_enc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP5rRLdixuDH"
      },
      "outputs": [],
      "source": [
        "y_pre=model.predict(xtest_glove)\n",
        "y_pre=np.round(y_pre).astype(int).reshape(3263)\n",
        "sub=pd.DataFrame({'id': df_submission['id'].values.tolist(),'target':y_pre})\n",
        "sub.to_csv('submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================\n"
      ],
      "metadata": {
        "id": "VesWahWu_dzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 70\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "\n",
        "# zero pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "metadata": {
        "id": "5j22z7iY_dYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-pTk0Ok_lu_",
        "outputId": "fb49f2a7-9e5e-4b4b-9e81-f588969fad98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 25943/25943 [00:00<00:00, 181414.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     100,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "YqLxYoXjABEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=5, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVvls3zmAIKA",
        "outputId": "22e6b98c-120e-4b52-d196-d014fcdc9612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "35/35 [==============================] - 48s 1s/step - loss: 0.8833 - val_loss: 0.7997\n",
            "Epoch 2/5\n",
            "35/35 [==============================] - 44s 1s/step - loss: 0.8644 - val_loss: 0.7854\n",
            "Epoch 3/5\n",
            "35/35 [==============================] - 48s 1s/step - loss: 0.8527 - val_loss: 0.7946\n",
            "Epoch 4/5\n",
            "35/35 [==============================] - 40s 1s/step - loss: 0.8415 - val_loss: 0.7585\n",
            "Epoch 5/5\n",
            "35/35 [==============================] - 40s 1s/step - loss: 0.8246 - val_loss: 0.7633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64ddb38850>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Early Stopping**"
      ],
      "metadata": {
        "id": "JkgF1eADBbI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     100,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=10, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9elEHAI5AL4-",
        "outputId": "7a5ce95f-612c-46bf-901d-2b4e76f184e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "35/35 [==============================] - 129s 4s/step - loss: 1.0806 - val_loss: 0.9626\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 125s 4s/step - loss: 0.9840 - val_loss: 0.8907\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 123s 4s/step - loss: 0.9414 - val_loss: 0.8545\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 125s 4s/step - loss: 0.9164 - val_loss: 0.8512\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 124s 4s/step - loss: 0.9085 - val_loss: 0.8517\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 125s 4s/step - loss: 0.8940 - val_loss: 0.8221\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 126s 4s/step - loss: 0.8657 - val_loss: 0.7913\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 123s 4s/step - loss: 0.8527 - val_loss: 0.7955\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 125s 4s/step - loss: 0.8321 - val_loss: 0.7816\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 123s 4s/step - loss: 0.8182 - val_loss: 0.7267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64e0000210>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple bidirectional LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     100,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=5, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKLoJKLG0Xj",
        "outputId": "bf6fa4c6-7015-46d6-b1d6-cdff58d49ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "35/35 [==============================] - 307s 7s/step - loss: 1.0787 - val_loss: 0.9903\n",
            "Epoch 2/5\n",
            "35/35 [==============================] - 260s 7s/step - loss: 0.9730 - val_loss: 0.8726\n",
            "Epoch 3/5\n",
            "35/35 [==============================] - 260s 7s/step - loss: 0.9496 - val_loss: 0.8951\n",
            "Epoch 4/5\n",
            "35/35 [==============================] - 271s 8s/step - loss: 0.9265 - val_loss: 0.8859\n",
            "Epoch 5/5\n",
            "35/35 [==============================] - 266s 8s/step - loss: 0.9089 - val_loss: 0.8329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64d9e0fa10>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pretty close! Lets try two layers of GRU:**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZOd7NiTPHVHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     100,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QTfPd5HHOxu",
        "outputId": "a7885c5b-bea0-4d0e-e740-4774a3b8059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 272s 8s/step - loss: 1.0895 - val_loss: 1.0057\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 262s 7s/step - loss: 1.0151 - val_loss: 0.9325\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 246s 7s/step - loss: 0.9619 - val_loss: 0.9143\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 262s 7s/step - loss: 0.9362 - val_loss: 0.8447\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 260s 7s/step - loss: 0.9021 - val_loss: 0.8280\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 264s 8s/step - loss: 0.8840 - val_loss: 0.8235\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 265s 8s/step - loss: 0.8579 - val_loss: 0.7804\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 260s 7s/step - loss: 0.8372 - val_loss: 0.7915\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 261s 7s/step - loss: 0.8186 - val_loss: 0.7669\n",
            "Epoch 10/100\n",
            " 8/35 [=====>........................] - ETA: 3:27 - loss: 0.8058"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembling"
      ],
      "metadata": {
        "id": "K6o1M3MNX9MS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmvOIcc2X8dh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}